{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b28ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "import torch, datasets, sacremoses\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"flax-community/papuGaPT2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf0698",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efdcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples, block_size=512):\n",
    "    \n",
    "    concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = (len(concatenated[\"input_ids\"]) // block_size) * block_size\n",
    "\n",
    "    result = {}\n",
    "    for k, v in concatenated.items():\n",
    "        result[k] = [v[i:i + block_size] for i in range(0, total_length, block_size)]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe6a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"text\", data_files={\n",
    "   \"train\": \"pan_tadeusz_1_10.txt\",\n",
    "   \"validation\": \"pan_tadeusz_11.txt\",\n",
    "   \"test\": \"pan_tadeusz_12.txt\",\n",
    "})\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"text\"])\n",
    "\n",
    "\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65791225-d752-41e3-a3ab-3775a038a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = torch.tensor(logits)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    shift_logits = logits[..., :-1, :].reshape(-1, logits.shape[-1])\n",
    "    shift_labels = labels[..., 1:].reshape(-1)\n",
    "    loss = F.cross_entropy(shift_logits, shift_labels)\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return {\"perplexity\": perplexity}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b911f38-2aa6-4060-8523-7f5c5411f509",
   "metadata": {},
   "source": [
    "## Base check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d829ef-8a83-4aff-aaf7-722f397dc866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text before training:\n",
      " Jam jest Jacek – szef działu produkcji filmowej w jednej z firm produkujących w Polsce. „Jest nam nie tylko przykro, że to co się dzieje w branży filmowej może być postrzegane wyłącznie przez pryzmat polityki i przemysłu filmowego, ale też dlatego, że to, co robimy w mediach, nie jest naszym osobistym interesem.”\n",
      "„Z całym szacunkiem, ale nie rozumiem tego co robią ci wszyscy Ci z opozycji, a to, co robią media, nie tylko to, co robią politycy, nie jest polityką. To, co robią politycy, także to, co robią ludzie związani z branżą filmową, także to, co robią media, jest naszym interesem.”\n",
      "„A może jednak jest tak jak mówi – każdy widzi co innego. Tak jest wszędzie. W TVP to są ludzie, którzy coś pokazują i coś się na nich natykają. Nie jest to na pewno film, który mógłby się obronić przed jakąkolwiek krytyką, nie jest to też film, który mógłby coś zmienić.”\n",
      "„Z całą pewnością\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "prompt = \"Jam jest Jacek\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=200,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Generated text before training:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2250b84",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b2a57e-b63d-4f31-ab30-617d26012c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class GenerateTextCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, prompt=\"Jam jest Jacek\", max_length=200):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt = prompt\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        model = kwargs['model']\n",
    "        model.eval()\n",
    "\n",
    "        input_ids = self.tokenizer(self.prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_length=self.max_length,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=1.0,\n",
    "                repetition_penalty=1.2,\n",
    "                num_return_sequences=1\n",
    "            ) \n",
    "        \n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(f\"\\n--- Generated text after epoch {state.epoch}:\")\n",
    "        print(generated_text)\n",
    "        print(\"---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5eceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\litwi\\AppData\\Local\\Temp\\ipykernel_2768\\1935341375.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/240 08:21 < 02:06, 0.38 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.827408</td>\n",
       "      <td>124.885567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.747366</td>\n",
       "      <td>115.278801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.685000</td>\n",
       "      <td>4.711594</td>\n",
       "      <td>111.228004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.685000</td>\n",
       "      <td>4.692184</td>\n",
       "      <td>109.089920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.343000</td>\n",
       "      <td>4.686679</td>\n",
       "      <td>108.490974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.343000</td>\n",
       "      <td>4.685804</td>\n",
       "      <td>108.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.170200</td>\n",
       "      <td>4.686109</td>\n",
       "      <td>108.429070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.170200</td>\n",
       "      <td>4.687651</td>\n",
       "      <td>108.596245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 1.0:\n",
      "Jam jest Jacek, że go tu przyprowadzi! – Głos jej i twarz jego były zamyślone. Poruszona pytała co się stało ze mną? — Mówił do mnie: Ja dziś z nim pójdę na wesele po to tylko żebym była weselsza nie jako córka mojej matki; a w domu moim niech by ojciec przykazał rodzicom moich braciom trzymać córkę u siebie lub jeżeli kto może dać komukolwiek o tym wiedzieć pod rękę ojca swojego albo córki syna mego… A ja mu przyrzekłem mówić głośno gdy będzie nas obchodził dzień jak mój brat...\n",
      "— To on był królem Polski dzisiaj przez króla Jerzego II czyli Jana Kazimierza zwany - mówi panna Teodorowicz Ociepalska jeden spośród gości weselnych obok młodej panny siedzącej przed ołtarzem (to Helena), aby ją przywitać słowami pieśni \"Poranny prorok\" wyśpiewując swój wielki wiersz pt.: «Panie nasz miły Panie nasze». Ona także została matką chrzestną swego potomka Stanisława Wagińskiego zwanego „Wa\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 2.0:\n",
      "Jam jest Jacek jako ostatni z rodu Jagiellonów. W nim też mam moje imię, jak po włosku Jacku: to pan Jan; mój panie stryju! Mój ojcze — wyszeptał Jakub w czasie obiadu i razem usiedli do stołu na dziedzińcu zamku lub pałacu).Nie było łatwo ale zażegnałem jej niebezpieczeństwo raniąc ją mocno swym ciałem a tak się bacznie przysłuchiwałam jego żartom nie wiedząc dlaczego mi groził lecz sam gdy już skończyli jeść rozkazał odejść by uniknąć kary rzuconej przez swą siostrę Liwinę (Stelt), która mu wszystko wyjaśniała aby ocalić córkę od zarazy”.Po kilku godzinach wyszła wieczorem ze swej komnaty bez słowa pożegnania mówiąc kupiecowi „Umieścić wszystkich naszych tu obecnych braci moich przodków we dworze…Obaj panowie muszą mnie opuścić”Odszedłem więc pod mury zamczyska o którym miałem nadzieję powiedzieć że będę je pilnie widział tylko okiem szpiega mego ojca co ja ujrzę przy końcu\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 3.0:\n",
      "Jam jest Jacek, jak we śnie wyślizguje się mu nos.Wziął on od nich pacierz i rzekł: \"Ojcze wasz\" (Jezus).Idź stąd; idź nazajutrz(w końcu Janowi tak dopomóż Pan Bóg)\n",
      "Swojej matki nie znamy lecz możemy domyślać sie za co Bogu Ojcu służyć…Co ona by w tych chwilach mówiła?Może to jej była córka!Umyśliła sobie że niech ma dziecko z ojcem swego dziada-Żech wie jaka będzie przyszłość ich dzieci...Teraz my oboje mamy już swoje wnuki a nawet prawnukówNaśladuję ojca tej córki o tym kto ją zabił przed swym pokoleniemJacku panienku..Panie mój Ojcze wiesz jaki pan był dobry ze mnie dzieciak ?Ależ czy ja byłem dobrym Polakiem dla mojej siostrzenicy .Ale muszę cię zapytać ,jakim cudem twój ojciec kocha ciocię Zosię !Boś Ty Panie Boże mały chłopczyk ale mądry chłopak chociaż mi\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 4.0:\n",
      "Jam jest Jacek, niechże się on zająkną i jak by był z nimi ten szlachcic co to miał już od trzech lat gości:». «Czy ja byłem w domu?…» zapytał Hrabia. — Ja tak! To mi pany panowie panie mówić o tobie; prawda nie do wiary jestem dla tego pana na tym weselu mój pokój wynajmowany a więc muszę wam coś powiedzieć podsłuchałem rozmowę między sobą mówiąc »Jacku« lecz sam pan Tadeusz tam mieszkaBo przecież tu wszyscy ludzie słyszą jego imię bo mają we wsi zamek który został zburzony dawno przez Litwinów czy NiemcówW czasie wojny też nim było ale gdy przyszło carskie wojsko lub litewskie wojska gdzie ci inni są razem po drugiej stronie morza mieli broń taką ze stali wzięciJak ich wywieźli stąd przywieźć ranili głowę .Więc teraz mówię żem tylko tyle mówił kiedy mówiłem państwu moim iż ty byś choć trochę znał moje słowo ojczyste przed kim bym chciał opowiedzieć waszą historięNiechaj was ksiądz Horeszków pozna\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 5.0:\n",
      "Jam jest Jacek, że wnet u nas zamieszkasz;»Rzekł Piotr: «Co więc zrobiłeś?Idź pan na sejm!«Wyjęto go i zamknięli.Tymczasem znowu mu krzyknąłem po niemiecku o wpół do szóstejej wieczorem».    Wtem przybył Jan Sędziejowski z Ryczywody razem ze swym ojcem Tadeuszem (Getwit), a my staliśmy za stołem obok szlachcica gospodarza(Paprocki).Jakże trudno dziś poznać przyczynę jego aresztowania przez sądy kasztelana kwestarskiego czy innych guślarzy — chociaż ów urzędowy stan zna każdy Wojski lub sam się nim zajmował od lat młodzieńczych*.Stąd on nie był jeszcze znany nikomu prócz młodzieży szkolnej .Tak działo prawo czeskie[22] *Jakuś zwany Pająkiem ma dwie głowy* które niegdyś nosiły herby rodów litewskich czyli Rilskich…Ale tylko głowę*, co jak mi mówiono nieraz nazywano kozłem\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 6.0:\n",
      "Jam jest Jacek, że nie miałem co z nim gadać. —A cóż w tej dziwce było?!Zapomniałem tylko zadać mu kilka ważnych pytań:Bo gdzie ja jestem u licha i straszno jak ona na wsi żyje (Jak wszyscy się śmieją).Pojechałem do niej o piątej wieczorem;Raz czy dwa razy musiałem przerywać jej rozmowyI prosić ją bym przyszedł jutro znowu po obiadW niedzielę przed ósmą rano albo za dwie godzinyTen wielki przyjaciel był gotów wyjść jako gość sam panować nad swym wzrostemLedwie wziąłem go jeszcze pod nogiZbyt daleko mnie minął od miejsca naszego zamieszkaniaTo już prawie noc dla nas obuJest to dość ważne a bardzo tajemnicze by wiedzieć kto kogo otaczałOkocim kupiec Jankiel zwany ZdziechowskiNa Litwie tak zwani LisewieUmiał on być równie mądry niż jego sąsiadRektegryta(Stary Moskalom), której też nigdy dotąd nikt dobrzeNie ma takiego SoplicowaKowalstwa lecz ko\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 7.0:\n",
      "Jam jest Jacek. On mi to wysłowił: «Jacek!» — od tych wszystkich osób, które nas znają jako gościnność nasza; a ja mu tylko na ten znak mówię po polsku z francuzkiem Francuzem językiem francuskim i ojczystym rapéjem w obozie (Sędzio znał go jeszcze)».Wracamy? Jakimż prawem nie można było się kłócić o Polskę czy inne rzeczy narodowe jak właśnie ją nazywać Rzeczpospolitą Polską?!Nareszcie doszliśmy ku granicom ojczyzny naszej dawnej…Znów my sami musieliśmy mówić pro ducato – Francuzi inaczej niż Polak we zwyczajuI często już tu był czas wspomnieć polską mowę :DSiedzę przy pudle bez celu bo mam dość siedzenia przez kilka minut(Śmiech pana Hrabiego).Usłyszałem że jakieś ruchy mają za mnąWięc wyjdę przed dom żeby pogadać co słychać u ludzi moich lub ich znajomychA gdzie bywam częściej czyli jestem gościem obcym dla mnie krajuPosłuchałem gościa lecz on zaczął\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated text after epoch 8.0:\n",
      "Jam jest Jacek).Oddał życie za to co było.Za karę,ze go nie znaja;Ale gdy ja byłem w niewoli(Odyseję)Stary został przy życiu jak gdyby nigdy nic:I o tym że mnie z Jackiem chcieli spalić rzekł ScyzorykiemKrukaHrabia Dobrzyński*…«Niedźwiedź» — powtórzył szlachcic-odcisnął pięść i spojrzał prosto na Sędziego».Teraz się odwracał Sędzia już był bliski ukropu lecz cóż powie do oczu Wodzowi?    Lecz ten pierwszy raz tak bardzo przestraszył sędzięGodząc myśli jąkałAż sędzia wpadł we wściekłośćBo czuł pogardę dla tego człowieka ,byrny zwierzańca!Przerażenie ścisnęło serce Hrana .Znowu chciał zemścić siekierą a zaraz znowu uciekaćWtem ujrzał dwóch mężów idących razem pod ramięRozprawiając nad losem gadadłaSokoła (Witka),Atakujący Soplice\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=192, training_loss=4.329573790232341, metrics={'train_runtime': 508.8289, 'train_samples_per_second': 3.734, 'train_steps_per_second': 0.472, 'total_flos': 397163888640000.0, 'train_loss': 4.329573790232341, 'epoch': 8.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./decoder-pan-tadeusz\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"perplexity\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[GenerateTextCallback(tokenizer),  EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
